# Real-Time Scrap Classifier & Robotic Pick Simulation

Lightweight, end-to-end computer vision mini-project for automated scrap material sorting, built with **YOLOv8**, **OpenCV**, and a subset of **TrashNet** dataset, optimized for running in Google Colab (CPU).

---

## ðŸ“Œ Overview

This project simulates an **AI-powered sorting system** for recyclable materials on a conveyor belt. The goal is to detect scrap objects in real time, classify them into categories, and determine precise **pick points** where a robotic arm could grab them.

It is **not a production-grade system**, but a **mini proof-of-concept** that covers all stages of a vision pipeline â€” dataset preparation, model training, inference, and visualization â€” while staying lightweight enough for students and quick demos.

---

## ðŸŽ¯ Objectives

- **Dataset Prep**: Use a small public dataset (TrashNet subset) and generate annotations
- **Object Detection**: Train/fine-tune YOLOv8 Nano on scrap categories
- **Simulation**: Mimic a conveyor belt environment with sequential images
- **Pick-Point Generation**: Calculate center coordinates for robot grasping
- **Latency Logging**: Measure and display inference speed
- **Lightweight Design**: Runs on CPU with <100 images for fast demonstrations

---

## ðŸ— System Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TrashNet      â”‚â”€â”€â”€â–¶â”‚  Preprocessing   â”‚â”€â”€â”€â–¶â”‚  YOLOv8 Nano    â”‚
â”‚   Dataset       â”‚    â”‚  & Annotation    â”‚    â”‚  Training       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenCV        â”‚â—€â”€â”€â”€â”‚   Pick Points    â”‚â—€â”€â”€â”€â”‚   Real-time     â”‚
â”‚   Display       â”‚    â”‚   + Crosshairs   â”‚    â”‚   Inference     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Pipeline Flow
```
Input Images â†’ YOLOv8 Detection â†’ Bounding Boxes â†’ Pick Point Calculation â†’ OpenCV Display
     â†“              â†“                   â†“                â†“                    â†“
  640x640px    Confidence Scores    Center Coords    Crosshair Overlay   Frame Display
```

---

## ðŸ›  Technology Stack

| Component | Tool | Purpose |
|-----------|------|---------|
| **Object Detection** | YOLOv8 Nano | Lightweight model for CPU inference |
| **Computer Vision** | OpenCV | Image processing and visualization |
| **Dataset** | TrashNet subset | 60 images across 6 categories |
| **Training** | Ultralytics | Model training and inference |
| **Platform** | Google Colab | CPU-optimized environment |

---

## ðŸ” Implementation Details

### Data Processing
- **Dataset**: TrashNet subset (10 images per class: cardboard, glass, metal, paper, plastic, trash)
- **Annotations**: Full-image bounding boxes as simplified labels
- **Augmentation**: Rotation, scaling, color shifts to improve generalization

### Model Training
- **Architecture**: YOLOv8 Nano (3.2M parameters, 6.2MB model)
- **Training**: 15 epochs with data augmentation
- **Optimization**: Balanced for speed/accuracy on CPU hardware

### Real-time Simulation
- **Conveyor Simulation**: Sequential image display mimicking belt movement
- **Processing Pipeline**: Detection â†’ Classification â†’ Pick Point â†’ OpenCV Display
- **Performance Monitoring**: Real-time latency measurement printed to console

---

## ðŸ“Š Performance Results

### Detection Accuracy
| Class | Avg Confidence | Detection Rate |
|-------|----------------|----------------|
| Cardboard | 0.68 | 85% |
| Metal | 0.72 | 80% |
| Glass | 0.45 | 60% |
| Plastic | 0.52 | 65% |
| Paper | 0.41 | 55% |
| Trash | 0.38 | 50% |

### System Performance
- **Inference Speed**: 78ms per frame (~13 FPS)
- **Model Size**: 6.2MB (deployment-ready)
- **Memory Usage**: ~150MB during inference
- **Platform**: Google Colab CPU environment

---

## âš ï¸ Challenges & Learnings

### Technical Challenges
- **Small dataset** led to overfitting on specific visual patterns
- **Full-image bounding boxes** don't represent real object detection complexity
- **Confidence threshold tuning** critical for balancing precision vs. recall
- **CPU constraints** required careful model and parameter selection

### Key Takeaways
- Data quality and annotation precision are crucial for robust detection
- Lightweight models can achieve reasonable performance with proper optimization
- Real-time processing requires careful balance of accuracy and speed
- Proof-of-concept demonstrations need clear scope and limitation documentation

---

## ðŸš€ Future Enhancements

- Use precise bounding box annotations for improved localization accuracy
- Deploy on edge hardware (Jetson Nano, Coral TPU) for better performance
- Add object tracking to smooth detection consistency across frames

---
